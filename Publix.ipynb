{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16c13b8",
   "metadata": {},
   "source": [
    "# Writing Functions For Publix Web Scrape\n",
    "### Using this as a chance to get familiar with selenium and webdrivers\n",
    "- write click load more button function\n",
    "- write get page source function\n",
    "- scrape and organize the data once all have been loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15490651",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/__trlxz94xn8xd3lkm9cxcjm0000gn/T/ipykernel_23302/1433109740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from selenium.common.exceptions import [TheNameOfTheExceptionClass]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "#from selenium.common.exceptions import [TheNameOfTheExceptionClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0435f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "publix_url = \"https://www.publix.com/savings/weekly-ad/view-all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(page):\n",
    "    soup = BS(page, 'html.parser')\n",
    "    sales = soup.findAll('div', attrs = {'class':'p-grid-item'})\n",
    "    \n",
    "    title_attrs = {'class':'p-text paragraph-md normal default line-clamp title'}\n",
    "    deal_attrs = {'class':'p-text paragraph-sm strong default'}\n",
    "    valid_attrs = {'class':'valid-dates p-text paragraph-xxs normal default line-clamp'}\n",
    "    descrip_attrs = {'class':'description p-text paragraph-xs normal default line-clamp'} \n",
    "    \n",
    "    product_list = []\n",
    "    deal_list = []\n",
    "    valid_list = []\n",
    "    desc_list = []\n",
    "    for s in sales:\n",
    "        prod = s.find('span', title_attrs)\n",
    "        deal = s.find('span', deal_attrs)\n",
    "        valid = s.find('span', valid_attrs)\n",
    "        desc_container = s.find('span', descrip_attrs)\n",
    "        if prod:\n",
    "            product_list.append(prod.text.strip())\n",
    "        else:\n",
    "            product_list.append('NA')\n",
    "        if deal:\n",
    "            deal_list.append(deal.text.strip())\n",
    "        else:\n",
    "            deal_list.append('NA')\n",
    "        if valid:\n",
    "            valid_list.append(valid.text.strip())\n",
    "        else:\n",
    "            valid_list.append('NA')\n",
    "        if s.find('span', descrip_attrs):\n",
    "            desc_list.append(desc_container.find('span').text)\n",
    "        else:\n",
    "            desc_list.append('no description')\n",
    "    #create dataframe with dict\n",
    "    weekly_ad = {\n",
    "        'product':product_list,\n",
    "        'sale': deal_list,\n",
    "        'valid_date' : valid_list,\n",
    "        'description' : desc_list}\n",
    "    weekly_ad = pd.DataFrame(weekly_ad)\n",
    "    return weekly_ad\n",
    "def click_button(driver):\n",
    "    #find the button\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH,'//*[@id=\"main\"]/div[4]/div/div[2]/div[2]/div[4]/button')\n",
    "        button.click()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "        \n",
    "def main():\n",
    "    publix_url = \"https://www.publix.com/savings/weekly-ad/view-all\"\n",
    "    #start driver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(publix_url)\n",
    "    #give the page time to load\n",
    "    time.sleep(4)\n",
    "    #load in ALL the data with the load more button\n",
    "    #initialize loadmore to true\n",
    "    loadmore = True\n",
    "    while loadmore:\n",
    "        loadmore = click_button(driver) \n",
    "        time.sleep(4)\n",
    "    #one the whole page is loaded we get the page source to pull the data from\n",
    "    df = scrape_page(driver.page_source)\n",
    "    driver.quit()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubWeekly = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f29228",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"C:/Users/theoc/Documents/NSS/Capstone/data/publix_weeklyad_11-22.csv\"\n",
    "test.to_csv(savepath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c65bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e0280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubWeekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcf02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
